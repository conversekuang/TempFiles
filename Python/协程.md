### 协程

coroutine 协程：协程对象，**指一个使用async关键字定义的函数**，它的调用不会立即执行函数，而是会返回一个协程对象。协程对象需要注册到事件循环，由事件循环调用。

async/await 关键字：async定义一个协程，await用于挂起阻塞的异步调用接口。

<https://www.cnblogs.com/zhaof/p/8490045.html>

import asyncio

- await  执行效果与正常执行一致，也就是程序会阻塞在这里，进入调用的协程函数，执行完毕后再继续，也就是await字面意思。

- async 声明异步函数，调用一步函数可以得到协程对象



#### 协程的执行

- await调用

  这里谈谈 asyncio.await  func() 的作用。其实，个人感觉是程序员可以来控制协程什么时候可以交出控制权，当在协程中，遇到socket，网络请求等，需要等到很长时间且不会立马返回结果的情况下，可以通过await来将控制权交出，让其他协程能够执行。等到执行结果返回后。

  

  因此， 后是耗时的操作，用于让出控制权，所以一般都是async函数。

- asyncio.create_task()来创建任务

  用于加入到事件循环中。

  不会因为await而一直阻塞，而会调用其他task进行执行。

```python
import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    print('OK {}'.format(url))

#第一种写法
async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    for task in tasks:
        await task

#第二种写法
async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    await asyncio.gather(*tasks)

if "__name__" == "__main__":
    asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))
```

在gather函数中，gather(*coros_or_futures, loop=None, return_exceptions=False)。如果协程执行成功则返回结果，若执行不成功且参数return_exceptions=True，则将异常信息视作执行成功的结果。

- asyncio.run() 来触发运行



```python
#coding:utf-8
import asyncio
import time

async def corou1():
    print("corou 1, {}".format(time.perf_counter()))
    await asyncio.sleep(2) 	#协程await出控制权
    print("corou 1, {}".format(time.perf_counter()))
    
async def corou2():
    print("corou 2, {}".format(time.perf_counter()))
    # await asyncio.sleep(2)
    time.sleep(5) 		#模拟一直在执行某个任务
    print("corou 2, {}".format(time.perf_counter()))

async def corou3():
    print("corou 3, {}".format(time.perf_counter()))
    await asyncio.sleep(2) 	#协程await出控制权
    print("corou 3, {}".format(time.perf_counter()))

async def main():
    #要不断的通过create task将协程加入到同一个循环事件。在create_task()就是循环事件
    tasks = [asyncio.create_task(corou())for corou in [corou1,corou2,corou3] ]
    await asyncio.gather(*tasks)	#一定要让main协程await出控制权

if __name__ == "__main__":
    asyncio.run(main())
###########执行结果############
func 1, 0.3864962
func 2, 0.3866095
func 2, 5.386688
func 3, 5.387335
func 1, 5.3877248
func 3, 7.3883411
```

通过上述例子可以看出，协程corou1，corou2，corou3的执行顺序按照加入循环事件的顺序。协程corou1 通过 await asyncio.sleep(2) 让出控制权，协程corou2由于没有await让出控制权所以一直在执行。当corou2结束后，很显然corou1也已经执行完，但还是先执行协程corou3，等协程corou3通过await让出控制权后，协程corou1才执行。

从上可以看出：

- 协程是按照事件循环顺序执行。即使交出控制权的协程执行完毕任务后等待再次获取控制权完成剩余任务，也必须等到循环到该协程才能获得CPU控制权。不会由于该协程已经完成await的任务而直接给它。这就是解释，协程corou2执行完会继续执行协程corou3，而并非继续执行协程corou1。
- await是交出协程控制权的地方
- 从上述代码可以看出，协程中当执行耗时IO操作时，应及时释放控制权，否则其他协程即便完成任务也由于没有CPU控制权而无法继续执行任务。





**思考题**：协程如何实现回调函数

```python
在 python 3.7 及以上的版本中，我们对 task 对象调用 add_done_callback() 函数，即可绑定特定回调函数。回调函数接受一个 future 对象，可以通过 future.result() 来获取协程函数的返回值。

示例如下：

import asyncio

async def crawl_page(url):
    print('crawling {}'.format(url))
    sleep_time = int(url.split('_')[-1])
    await asyncio.sleep(sleep_time)
    return 'OK {}'.format(url)

async def main(urls):
    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]
    for task in tasks:
        task.add_done_callback(lambda future: print('result: ', future.result()))
    await asyncio.gather(*tasks)
```



> 表示赞同的评论

- 开发者要提前知道一个任务的哪个环节会造成I/O阻塞，然后把这个环节的代码异步化处理，并且通过await来标识在任务的该环节中断该任务执行，从而去执行下一个事件循环任务。这样可以充分利用CPU资源，避免CPU等待I/O造成CPU资源白白浪费。当之前任务的那个环节的I/O完成后，线程可以从await获取返回值，然后继续执行没有完成的剩余代码。
  由上面分析可知，如果一个任务不涉及到网络或磁盘I/O这种耗时的操作，而只有CPU计算和内存I/O的操作时，协程并发的性能还不如单线程loop循环的性能高。



- 老师，我测试了一下，协程的方式只会跑满一个CPU内核，而传统多进程并发的方式可以利用到所有的CPU内核，这个协程的方式能把所有cpu内核都用上吗，怎么做呢？

  如何将协程跑满CPU？



- CPU-bound的任务主要是multi-processing，IO-bound的话，如果IO比较快，用多线程，如果IO比较慢，用asyncio，因为效率更加高

